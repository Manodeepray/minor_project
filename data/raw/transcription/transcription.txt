huge a size of new j e j square okay okay the residual okay so we have everything we need rushing a little bit here but so the point i want to make his if you have a sub space and you want to find the closest point in that sub space to axe that's the same as minimizing over all the possible directions on a sub space this just and square doesn't square squared make the computation easier that alpha i have you solve it is going to break apart in reasons going to break apart as when you multiply it apart like this you're going to get products of view i knew j they will all go away so all you'll be left with is a bunch of the alpha eyes an alpha jays that are multiply and exactly the same way as the one case you should check that and this is you know if if you're rusty on this is from your linear algebra class and i'm super happy to write it out in more detail if that confuses you but for now hopefully we can we can just move to this guy this thing here is the residual that says how close am i what's my distance from axe to the sub space and that's going to feature prominently in what we do next please so so what we're going to try and do is we're going to try and find a low dimensional space and i'll describe how we're going to do it next and pc a when we're talking about what's the principal component of variation we're going to search across all the directions when we're looking for the principal component were to say which one of them has this for example there are two ways you can find peace a but has the smallest residual or we will be equivalent maximizes the amount of alpha the amount we projected onto the subset guy so there are two ways you can do this so we can find peace yea by one maximizing the projected amount that means trying to make alpha as large as possible right so if you give me a sub space which is a section of of of vectors i can compute the alphas by solving this problem i want to compute something so that direction so that for almost all the data points my alphas are as large as possible so getting back in the earlier question about why did i say that direction was the principal component of variation is because if i put it in that direction i was kind of explaining the most and the residuals the errors were small duly these residuals for every point or as small as possible and we're going to minimize those in one second echo have we did so awesome question no not necessarily right because for example think about even if we we need we normalized it there may be one direction that explains for example the temperature how far it is away from the heat source back to my thousand temperature sensor example there's one direction that explains that but there still could be very a asians and other directions that are not captured by any other process and so they would be orthogonal to that does not necessary that the that the all even know all the directions on average are normalized that for any particular point like if there's a correlation wouldn't would would be the same we have so all the actors or or are put into the same scale by taking each individual component and computing example sample variants yeah multiplying by diagonally tricks please just as between or at home or just a question so here alpha alpha is is basically t so it tells you how far along the line you're going to go so alphas constrained to live on the line so when we minimize or over alpha were minimizing that's coordinate along the line and as well defined right there's only there's a closest point here right we know that kind of intuitively from you know undergrad whatever whatever geometry we took great like that there's a closest point but this proves it right awesome cool please yeah so it's either you want to you want to capture as much of your data as possible and in a linear case it's either you want to be want to capture as much as possible or minimize the residual were turn out to be equivalent because here if you look at it because these are unit vectors beijing alpha jays bigger like if you if i had two sets of use you know you can i'm comparing them if the alphas are bigger for this one on average than for this one the nasa's that they capture more of my data because they're projection the alphas are defined by the use or it so that's why in the component principal component of direction right so what does boils down to i'll just do one of the methods the maximization one you have to the other one in your homework by the way so i am one reason to pay attention this says look over all the directions sorry you  okay just as look over all that are actions that are out there dot them into the dataset this is alpha right as the alpha we're just talking about and try to maximize the one that captures most of it so if you imagine me sweeping that line across the earlier dataset or looking here right here and i'm sweeping that line here here here my arse all from the origin sorry going here hear clearly this captures much more the office or much larger than they are here just take a dot products right because it just projecting onto a relatively narrow band doesn't capture as much spread and want more spread right it's quadratic me more spread okay so how do we solve this question here well we need a couple of facts guy maybe we will pick this up in a little bit yeah it's probably best to let me ask me questions about particular spot will talk come back about how to solve this kind of equation and a second an eloquent questions about this piece as decision you this point so i use by maximize loser austria's you used i agree sure what you are you use or lost the on the yeah well the leader ones that exactly right they can capture the most that is a think about were going back to our early example this is this is important we were going to have you wanted you to that was like our basis right that's thornley what's called we want to capture so it turns out that the the squares of alpha one an alpha to some to the sky where of excise components like their norms are the same okay that's just a mathematical fact because these are these are this is what our bases so so the point is as we want to capture of these two were going to throw away alpha to if we only are allowed to compute one component so we want that the you that we select to be the one that for most of the data capture some relevant information right like if we found something like this direct one is mostly orthogonal to where the line that the data lives on so almost everybody's going to have like a projection that's really small like the data when i project onto the line is you can be cluster really really tightly together whereas of i cluster if i project onto this line it's still gonna be nice and spread out and this mathematically just says that it corresponds to either making sure that the alpha as overall or we're very close to the axis of their larger on average or that the amount that i lose this is a residual is the amount that i lose from the other directions is equivalent me small and an end for for pc a and you could he and space this is the case not relevant first class but there are other demand there their other kinds of geometries were that's not true this happens to be true for he couldn't jump if you decide to take non euclidean geometry screen course what does o x i let me just read it again nice catch eyes on show a very well with this pen and my handwriting which is criminals says he uses a free just assume it's an eye but that's what goes on right so we're think about with this equation to saying with this optimization saying as as pick over all use that are there we're normalizing come back to i went on ice is really matter too much but we want to do is explain as much of the data as we can awesome so next time we will cover a little bit of eigenvalues and how we saw this is a disease and eigenvalue problem and will cover the cocktail problem as well and you saw a little bit as cause pc i think so much for your time intention toxin 